reported-speech-latin/
│
├── README.md
├── LICENSE
├── CITATION.cff
│
├── data/
│   ├── README.md
│   ├── processed/
│   │   ├── train.json
│   │   ├── dev.json
│   │   └── test.json
│   └── statistics/
│
├── configs/
│   ├── laberta.yaml
│   ├── philberta.yaml
│   └── latinbert.yaml
│
├── src/
│   ├── train.py
│   ├── evaluate.py
│   └── run_experiments.py
│
├── results/
│   └── tables/
│
├── requirements.txt
└── .gitignore


# Model
model_name: "LaBERTa"
pretrained_model: "la-bert-base"

# Tokenizer
max_seq_length: 512
padding: "max_length"
truncation: true

# Task
task_type: "token_classification"
label_scheme: "binary"        # reported / non-reported
span_level: true              # NOT sentence-based
use_punctuation: true         # or false

# Data
train_file: "data/processed/train.json"
dev_file: "data/processed/dev.json"
test_file: "data/processed/test.json"
token_level_labels: true

# Training
epochs: 30
batch_size: 8
learning_rate: 2e-5
weight_decay: 0.01
warmup_steps: 0
gradient_accumulation_steps: 1

# Evaluation
evaluation_strategy: "epoch"
metrics:
  - accuracy
  - precision
  - recall
  - f1
  - pr_auc

# Reproducibility
seed: 42
fp16: false


## Splitting strategy

The dataset is split at the level of `microsection`, which corresponds to
span-level discourse units. All tokens belonging to the same microsection
are assigned to the same split (train/dev/test) to prevent information leakage
across spans.

The split proportions are 70% training, 20% validation, and 10% test,
with a fixed random seed (42).


The dataset is split at the level of the `microsection` field, corresponding
to span-level discourse units. We randomly assigned 70% of the 
sections to training, 20% to validation, and 10% to the
test sets using a fixed random seed (42). No section
appears in more than one split. All tokens belonging to the same section
are assigned to the same split. 


python src/data/preprocessing.py \
  --input_csv data/raw/dataset.csv \
  --out_dir 


python src/train_robertabasedmodel.py \
  --model_name bowphs/LaBerta \
  --output_dir outputs/laberta_finetuned


latin_bert/
  config.json
  model.safetensors (or pytorch_model.bin)
  vocab.txt


python train_latinbert.py --model_dir /path/to/latin_bert


python src/latinbert_finetuning/train_latinbert.py \
  --model_dir /Users/agustindei/Documents/NLP/Projet_sorbonne/Fine_tuning/LatinBert/latin_bert \
  --output_dir outputs/latinbert_finetuned